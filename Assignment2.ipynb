{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, sentiwordnet as swn\n",
    "from nltk.corpus.reader.tagged import TaggedCorpusReader\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import csv\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Preprocess: Preprocessing corpus ====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae517672f5241e0b6f7e79c10c3375e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57340.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess. Preprocessing corpus\n",
    "# =====\n",
    "# * Get some portion of sentences from corpus (default: all sentences)\n",
    "# * Filter words which are not alphabetio\n",
    "# * Make words to the lower case\n",
    "# * Get POS tags of sentences if corpus is not already tagged\n",
    "\n",
    "print(\"==== Preprocess: Preprocessing corpus ====\")\n",
    "\n",
    "using_corpus = brown\n",
    "sentences_portion = 1\n",
    "\n",
    "corpus_tagged = isinstance(using_corpus, TaggedCorpusReader)\n",
    "\n",
    "sentences = using_corpus.tagged_sents() if corpus_tagged else using_corpus.sents()\n",
    "sentences = sentences[:int(len(sentences) * sentences_portion)]\n",
    "\n",
    "if corpus_tagged:\n",
    "    sentences = [\n",
    "        [\n",
    "            (word.lower(), tag) for word, tag in words if word.isalpha()\n",
    "        ] for words in tqdm(sentences)\n",
    "    ]\n",
    "\n",
    "else:\n",
    "    sentences = [\n",
    "        [\n",
    "            (word.lower(), tag) for word, tag in nltk.pos_tag(words) if word.isalpha()\n",
    "        ] for words in tqdm(sentences)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Stage 0: Extracting Lexical Items ====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce8e1d68c934f08a8ec2f3b850ba475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57340.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adverbs: 436\n",
      "Predicates: 858\n",
      "Bigrams: 1495\n"
     ]
    }
   ],
   "source": [
    "# 0. Extracting Lexical Items\n",
    "# =====\n",
    "# * Find adverb + predicate pairs from corpus\n",
    "\n",
    "print(\"==== Stage 0: Extracting Lexical Items ====\")\n",
    "\n",
    "adverbs = {}\n",
    "adverbs_all = {}\n",
    "predicates = {}\n",
    "predicates_all = {}\n",
    "bigrams = {}\n",
    "\n",
    "for tokens in tqdm(sentences):\n",
    "    for index, (word, pos) in enumerate(tokens):\n",
    "        # Count adjectives\n",
    "        if pos in ('JJ', 'JJR', 'JJS'):\n",
    "            if word not in predicates_all:\n",
    "                predicates_all[word] = 0\n",
    "            \n",
    "            predicates_all[word] += 1\n",
    "            continue\n",
    "        \n",
    "        if pos != 'RB':\n",
    "            continue\n",
    "        \n",
    "        if len(tokens) <= index + 1:\n",
    "            continue\n",
    "        \n",
    "        # Count adverbs\n",
    "        if word not in adverbs_all:\n",
    "            adverbs_all[word] = 0\n",
    "        \n",
    "        adverbs_all[word] += 1\n",
    "        \n",
    "        next_word, next_pos = tokens[index + 1]\n",
    "        \n",
    "        # Not using ('RB', 'RBR', 'RBS') as it contains some collocations like nearly as, ...\n",
    "        if next_pos not in ('JJ', 'JJR', 'JJS'):\n",
    "            continue\n",
    "        \n",
    "        # Count adverbs with adjectives\n",
    "        if word not in adverbs:\n",
    "            adverbs[word] = 0\n",
    "        \n",
    "        adverbs[word] += 1\n",
    "        \n",
    "        # Count adjectives with adverb\n",
    "        if next_word not in predicates:\n",
    "            predicates[next_word] = 0\n",
    "        \n",
    "        predicates[next_word] += 1\n",
    "        \n",
    "        # Count (adverb, adjective) bigrams\n",
    "        bigram = (word, next_word)\n",
    "        if bigram not in bigrams:\n",
    "            bigrams[bigram] = 0\n",
    "        \n",
    "        bigrams[bigram] += 1\n",
    "\n",
    "print(\"Adverbs: %d\" % len(adverbs))\n",
    "print(\"Predicates: %d\" % len(predicates))\n",
    "print(\"Bigrams: %d\" % len(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Stage 1: Filter rare adverbs ====\n",
      "225 adverbs have been invalidated\n",
      "211 adverbs left\n"
     ]
    }
   ],
   "source": [
    "# 1. Filtering rare adverbs\n",
    "# =====\n",
    "# * Filter some adverbs which doesn't appear too much\n",
    "#   as it is hard to determine how restrictive it is\n",
    "\n",
    "print(\"==== Stage 1: Filter rare adverbs ====\")\n",
    "\n",
    "appear_threshold = 2 # int(len(sentences) * 0.0003)\n",
    "\n",
    "# Filtering rare adverbs\n",
    "rare_adverbs = {}\n",
    "def filter_adverbs(adverb, appear_count):\n",
    "    if appear_count < appear_threshold:\n",
    "        rare_adverbs[adverb] = appear_count\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "adverbs = {\n",
    "    adverb: appear_count\n",
    "    for adverb, appear_count in adverbs.items()\n",
    "    if filter_adverbs(adverb, appear_count)\n",
    "}\n",
    "\n",
    "# Filtering bigrams & predicates by rare adverbs\n",
    "def filter_bigrams(bigram, appear_count):\n",
    "    adverb, predicate = bigram\n",
    "    if adverb not in rare_adverbs:\n",
    "        return True\n",
    "    \n",
    "    # Invalidate predicates\n",
    "    predicates[predicate] -= appear_count\n",
    "    return False\n",
    "\n",
    "bigrams = {\n",
    "    bigram: appear_count\n",
    "    for bigram, appear_count in bigrams.items()\n",
    "    if filter_bigrams(bigram, appear_count)\n",
    "}\n",
    "\n",
    "predicates = {\n",
    "    predicate: appear_count\n",
    "    for predicate, appear_count in predicates.items()\n",
    "    if appear_count > 0\n",
    "}\n",
    "\n",
    "print(\"%d adverbs have been invalidated\" % len(rare_adverbs))\n",
    "print(\"%d adverbs left\" % len(adverbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Stage 2: Get restrictiveness of adverbs ====\n",
      "[('pitifully', ('small', 1.0)), ('childishly', ('merry', 1.0)), ('psychically', ('blind', 1.0)), ('inversely', ('proportional', 0.6)), ('extraordinarily', ('patient', 0.5)), ('demonstrably', ('incapable', 0.5)), ('ethically', ('acceptable', 0.5)), ('healthily', ('individual', 0.5)), ('delightfully', ('refreshing', 0.5)), ('grotesquely', ('unshaven', 0.5))]\n"
     ]
    }
   ],
   "source": [
    "# 2. Get restrictiveness of adverbs\n",
    "# =====\n",
    "# * Find how restrictive an adverb is by getting max frequency of a certain verb / adjective\n",
    "#   coming with the adverb among the whole count of verb / adjective\n",
    "#\n",
    "# (Restrictiveness is higher if the adverb comes mostly with a certain verb / adjective)\n",
    "\n",
    "\n",
    "print(\"==== Stage 2: Get restrictiveness of adverbs ====\")\n",
    "\n",
    "adverb_max_collocation = {}\n",
    "for (adverb, predicate), appear_count in bigrams.items():\n",
    "    appear_percentage = appear_count / (adverbs_all[adverb]) # (adverbs[adverb])\n",
    "    \n",
    "    if (adverb not in adverb_max_collocation) or \\\n",
    "        (adverb_max_collocation[adverb][1] < appear_percentage):\n",
    "            \n",
    "        adverb_max_collocation[adverb] = (predicate, appear_percentage)\n",
    "\n",
    "print(sorted(\n",
    "    adverb_max_collocation.items(),\n",
    "    key=lambda x: x[1][1],\n",
    "    reverse = True\n",
    ")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Stage 3: Filtering objective adverbs ====\n",
      "74 adverbs have been filtered\n",
      "1 adverbs have been passed\n",
      "['almost', 'probably', 'suddenly', 'also', 'increasingly', 'literally', 'potentially', 'possibly', 'uniquely', 'pitifully', 'usually', 'sometimes', 'sufficiently', 'heretofore', 'mostly', 'there', 'frequently', 'financially', 'relatively', 'primarily', 'militarily', 'simultaneously', 'widely', 'ethically', 'partly', 'notably', 'perhaps', 'economically', 'partially', 'ever', 'deeply', 'once', 'merely', 'continuously', 'therefore', 'thus', 'purely', 'previously', 'indeed', 'so', 'hitherto', 'proportionately', 'progressively', 'formerly', 'especially', 'currently', 'supposedly', 'rapidly', 'personally', 'occasionally', 'culturally', 'again', 'recently', 'specially', 'socially', 'moreover', 'unusually', 'here', 'vaguely', 'politically', 'admittedly', 'ultimately', 'similarly', 'internationally', 'characteristically', 'largely', 'distinctly', 'eventually', 'normally', 'semantically', 'childishly', 'psychically', 'maybe', 'finally']\n"
     ]
    }
   ],
   "source": [
    "# 3. Filtering objective adverbs\n",
    "# =====\n",
    "# * Filter objective adverbs, which min of obj_score of sentiwordnet is more than 0.9\n",
    "#   as there are many non-intensifiers like adverbs of frequency(usually, sometimes, ...),\n",
    "#   which usually have high obj_score\n",
    "\n",
    "print(\"==== Stage 3: Filtering objective adverbs ====\")\n",
    "\n",
    "object_adverbs = []\n",
    "passed_count = 0\n",
    "for adverb, (predicate, appear_percentage) in adverb_max_collocation.items():\n",
    "    senti_synsets = list(swn.senti_synsets(adverb))\n",
    "    \n",
    "    min_obj = None\n",
    "    for senti_synset in senti_synsets:\n",
    "        if min_obj is None or senti_synset.obj_score() < min_obj:\n",
    "            min_obj = senti_synset.obj_score()\n",
    "    \n",
    "    if min_obj is None:\n",
    "        passed_count += 1\n",
    "        continue\n",
    "    \n",
    "    if min_obj > 0.9:\n",
    "        object_adverbs.append(adverb)\n",
    "\n",
    "print(\"%d adverbs have been filtered\" % len(object_adverbs))\n",
    "print(\"%d adverbs have been passed\" % passed_count)\n",
    "print(object_adverbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Stage 4: Filtering the results ====\n"
     ]
    }
   ],
   "source": [
    "# 4. Filtering the results\n",
    "# =====\n",
    "# * Filter object_adverb containing sets from collocations\n",
    "# * Sort collocations by its restrictiveness\n",
    "\n",
    "print(\"==== Stage 4: Filtering the results ====\")\n",
    "\n",
    "result = sorted(\n",
    "    [\n",
    "        (key, value, appear_percentage)\n",
    "        for key, (value, appear_percentage) in adverb_max_collocation.items()\n",
    "        if key not in object_adverbs\n",
    "    ],\n",
    "    key=lambda x: x[2],\n",
    "    reverse = True\n",
    ")[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Stage 5: Saving the results ====\n",
      "0 inversely proportional\n",
      "1 extraordinarily patient\n",
      "2 demonstrably incapable\n",
      "3 healthily individual\n",
      "4 delightfully refreshing\n",
      "5 grotesquely unshaven\n",
      "6 academically talented\n",
      "7 noticeably longer\n",
      "8 startlingly bright\n",
      "9 amazingly light\n",
      "10 blissfully unaware\n",
      "11 empirically successful\n",
      "12 extremely conservative\n",
      "13 professedly benevolent\n",
      "14 inherently incapable\n",
      "15 conspicuously absent\n",
      "16 strikingly effective\n",
      "17 commercially available\n",
      "18 intrinsically evil\n",
      "19 enormously long\n",
      "20 cruelly distant\n",
      "21 mutually exclusive\n",
      "22 mentally ill\n",
      "23 intellectually sterile\n",
      "24 sexually selfish\n",
      "25 artistically successful\n",
      "26 immensely fertile\n",
      "27 hopelessly inadequate\n",
      "28 endlessly enchanting\n",
      "29 warmly melodious\n",
      "30 uniformly excellent\n",
      "31 strangely disquieting\n",
      "32 bitterly cold\n",
      "33 perfectly conceivable\n",
      "34 morally proper\n",
      "35 positively indecent\n",
      "36 curiously sleepy\n",
      "37 oddly sibilant\n",
      "38 upward mobile\n",
      "39 technically original\n",
      "40 remarkably elaborate\n",
      "41 vividly real\n",
      "42 stiffly motionless\n",
      "43 substantially empty\n",
      "44 painfully obvious\n",
      "45 dramatically coherent\n",
      "46 unexpectedly difficult\n",
      "47 emotionally secure\n",
      "48 nonetheless considerable\n",
      "49 solidly middle\n",
      "50 utterly unexpected\n",
      "51 terribly sorry\n",
      "52 strictly unallocable\n",
      "53 wholly new\n",
      "54 readily available\n",
      "55 seemingly remote\n",
      "56 surprisingly orthodox\n",
      "57 plainly right\n",
      "58 totally absent\n",
      "59 typically american\n",
      "60 reasonably comparable\n",
      "61 consistently demonstrable\n",
      "62 virtually impossible\n",
      "63 basically distasteful\n",
      "64 physically sound\n",
      "65 wildly experimental\n",
      "66 entirely different\n",
      "67 constantly full\n",
      "68 essentially intact\n",
      "69 altogether satisfying\n",
      "70 forever dead\n",
      "71 roughly chronological\n",
      "72 thoroughly criminal\n",
      "73 barely intolerable\n",
      "74 equally big\n",
      "75 gently deep\n",
      "76 openly abusive\n",
      "77 invariably compelling\n",
      "78 closely adjacent\n",
      "79 truly neutral\n",
      "80 seldom hungry\n",
      "81 no such\n",
      "82 presently immeasurable\n",
      "83 specifically regional\n",
      "84 otherwise available\n",
      "85 inevitably weaker\n",
      "86 rarely thick\n",
      "87 quietly insistent\n",
      "88 slightly finer\n",
      "89 directly proportional\n",
      "90 hardly necessary\n",
      "91 easily accessible\n",
      "92 necessarily applicable\n",
      "93 heavily indebted\n",
      "94 properly mindful\n",
      "95 immediately evident\n",
      "96 completely charming\n",
      "97 hence effective\n",
      "98 generally favorable\n",
      "99 apparently simple\n"
     ]
    }
   ],
   "source": [
    "# 5. Saving the results\n",
    "# =====\n",
    "# * Save the results from stage 4 as a csv and print it out\n",
    "\n",
    "print(\"==== Stage 5: Saving the results ====\")\n",
    "\n",
    "with open('results.csv', 'w', encoding='utf-8', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    for index, (key, value, _) in enumerate(result):\n",
    "        writer.writerow((key, value))\n",
    "        print(\"%d %s %s\" % (index, key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
